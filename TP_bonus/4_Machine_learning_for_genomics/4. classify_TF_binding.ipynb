{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpI9eESpkREM"
   },
   "source": [
    "# Ex1: Onehot coding DNA\n",
    "\n",
    "Write a function called **onehot_dna(dna_str)** that allows to encode a DNA segment where each base is encoded as a vector of all zeros except one in a specific position. The result of this function is an array numpy.  DNA is a long chain of repeating bases strung together. There are 4 bases: A, C, G, T. For example, \"AACCCAAATCGGGGG\" is a DNA segment.\n",
    "\n",
    "\n",
    "\n",
    "For example, **onehot_dna('AAT')** should return\n",
    "\n",
    "array([[1, 0, 0, 0],\n",
    "       [1, 0, 0, 0],\n",
    "       [0, 0, 0, 1]])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbhaCZP1moii"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM-BaQiGo82A",
    "outputId": "a7357e07-2c79-4d10-be96-aa0d8520b702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_dna('AAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkSQo19z60n1"
   },
   "source": [
    "# Deep learning to classify Transcription Factor Biding\n",
    "\n",
    "\n",
    "In the next exercises, we will learn how to use Deep learning to predict whether a segment of DNA does include or does not include a sit where JUND binds. (JUND is a particular transcription factor).\n",
    "\n",
    "In this purpose, we will use data that is extracted from the chapter 6 of the book: 'Deep learning for the life science'. This book is written by B.Ramsundar, P.Eastman, P. Walters and V.Pande.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the Wikipedia page of the Jund transcription factor, explain what is the use of such protein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data consist of DNA segments that have been split up from a full chromosome. Each segment is of 101 bases long and has been labeled to indicate whether it does or does not include a site where JUND binds to.\n",
    "\n",
    "\n",
    "This is a binary classification problem.\n",
    "The process of creating a PyTorch neural network binary classifier consists of several steps:\n",
    "\n",
    "1. Prepare the training and test data\n",
    "\n",
    "2. Implement a Dataset object to serve up the data\n",
    "\n",
    "3. Design and implement a neural network\n",
    "\n",
    "4. Write code to train the network\n",
    "\n",
    "5. Write code to evaluate the model (the trained network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XS8a5oOmOjqO"
   },
   "source": [
    "# Ex 2:  Load Data\n",
    "\n",
    "The data is available here : https://drive.google.com/drive/folders/1-nrTvNvEZo6Px1pnT7IeotKZR7p365UJ?usp=sharing\n",
    "\n",
    "1. With the help of the joblib library, load the following files for training set:  **y_train.joblib**, **X_train.joblib**  and then store the results in variables **y_train, X_train** ,respectively.\n",
    "\n",
    "2. Do the same thing for the test set: load  **y_test.joblib**, **X_test.joblib**  and then store the results in variables **y_test, X_test**, respectively.\n",
    "\n",
    "3. What are the shape of **X_train** and **y_train** ? How many DNA segments are there in traning set ?\n",
    "\n",
    "4. Display a DNA segment from **X_train** (using matplotlib.pyplot.imshow ).\n",
    "\n",
    "5. Plot the histogram of **y_train** to see whether data is imbalanced or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB5Y5StQezcZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMLs0OOTV4E5"
   },
   "outputs": [],
   "source": [
    "''' Tests X_train, y_train '''\n",
    "assert(X_train.shape == (4672, 101, 4))\n",
    "assert(y_train.shape ==(4672, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9g9rlIr2AAy6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RO7DeSen_W_h"
   },
   "outputs": [],
   "source": [
    "''' Tests X_test, y_test'''\n",
    "assert(X_test.shape == (584, 101, 4))\n",
    "assert(y_test.shape ==(584, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "TceRZcS3MENp",
    "outputId": "25a06914-8dbe-425c-f6eb-d0627b622bac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EajNPJrnAmde"
   },
   "source": [
    "# Ex 3: Convert numpy array to tensor pytorch\n",
    "\n",
    "As you see in the previous exercise, **X_train** consists of 4672 segments. Each segment is encoded by 0 and 1 (one-hot encoding).\n",
    "\n",
    "\n",
    "1. Convert numpy array **X_train**, **y_train** into pytorch tensor. Reshape **X_train** to (4672, 4, 101). Note that the type of **X_train** and **y_train** should be float.\n",
    "\n",
    "2. Do the same thing for **X_test** and **y_test**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8eedW_yPUKu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrBcHzR-E-yR"
   },
   "outputs": [],
   "source": [
    "''' Tests X_train_ts, y_train_ts '''\n",
    "assert(type(X_train_ts) is torch.Tensor)\n",
    "assert(type(y_train_ts) is torch.Tensor)\n",
    "assert(X_train_ts.shape == (4672, 4, 101))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wn_0dOuVHWhs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_it3skAH0Yt"
   },
   "outputs": [],
   "source": [
    "''' Tests the above ToDo. '''\n",
    "assert(type(X_test_ts) is torch.Tensor)\n",
    "assert(type(y_test_ts) is torch.Tensor)\n",
    "assert(X_test_ts.shape == (584, 4, 101))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEYJBjBdg547"
   },
   "source": [
    "# Ex4: Create Dataset\n",
    "In order to train a deep learning model with Pytorch, we need a pytorch dataset.\n",
    "The DNADataset class below allows for creating a pytorch Dataset from DNA segments and their labels.\n",
    "\n",
    "1. Using this class, create a dataset for training set. You should call it **train_dataset**\n",
    "\n",
    "2. Create **Dataloader** from **train_dataset**. You should call it **train_loader**.\n",
    "\n",
    "3. Do the same thing for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkvyOQVggLz_"
   },
   "outputs": [],
   "source": [
    "class DNADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dna, labels):\n",
    "        self.labels = labels\n",
    "        self.dna = dna\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        frag_dna = self.dna[idx]\n",
    "\n",
    "        sample = {'DNA': frag_dna, 'Class': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_d7J-rFbiig"
   },
   "source": [
    "**train_loader** is a generator. To get data out of it, you need to loop through it or convert it to an iterator and call next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJQK0ZaLMpKF",
    "outputId": "76fb9583-e609-4e26-e954-1c88af29b5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a batch data  torch.Size([32, 4, 101])\n",
      "Shape of label torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Run this to test your data loader\n",
    "data = next(iter(train_loader))\n",
    "dna = data['DNA']\n",
    "label = data['Class']\n",
    "print(\"a batch data \", dna.shape)\n",
    "print(\"Shape of label\", label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDcbP17Rb2xt"
   },
   "source": [
    "# Design and implement a convolutional neural network\n",
    "\n",
    "Now, it's time to build your model. This is a binary classification problem. We can use a convolution neural network, just like an image classification problem. However, since the size of a DNA segment is (4, 101), we will use 1D convolution instead of 2D convolution.\n",
    "\n",
    "\n",
    "\n",
    "Firstly, we will test how does a 1D convolution work on our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlPP4E3UfRYe"
   },
   "source": [
    "# EX 5: 1D Convolution\n",
    "\n",
    "1. With the help of the torch.nn.Conv1d class, create a 1D convolutional layer. You need to choose values for the following parameters: **in_channels**, **out_channels**, **kernel_size**.\n",
    "\n",
    "\n",
    "2. Apply this layer to **dna_seg** below. What is the size of the output ?\n",
    "\n",
    "\n",
    "3. [Optional] Display the output by using matplotlib.pyplot.imshow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9y0yRXhhj1F"
   },
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "dna_seg = data['DNA']\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJ9uE489imxl",
    "outputId": "b57cbf60-51b3-4746-e815-f58e24772b90"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H26rAy0wkbca"
   },
   "source": [
    "# EX 6: Build a model\n",
    "\n",
    "Create a 3 layer 1-dimensional network to classify the TF binding sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_bs8O3lhB7m"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepDNA(nn.Module):\n",
    "\n",
    "  pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVbFqM4laclu"
   },
   "source": [
    "# Ex 7 Test the model\n",
    "\n",
    "\n",
    "1. Create an instance of the DeepDNA class named **net**.\n",
    "\n",
    "2. Print out the variable **net** to see detailed information about the model.\n",
    "\n",
    "3. Pass **dna_seg** below to **net** in order to  test if your model **net** works well.\n",
    "\n",
    "4. What is the size of the output ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ladQCir7btvX",
    "outputId": "557662ec-4e25-47aa-dd92-ee56348aeab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output of the model  tensor([[0.4803],\n",
      "        [0.4815],\n",
      "        [0.4809],\n",
      "        [0.4797],\n",
      "        [0.4824]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#data = next(iter(train_loader))\n",
    "dna_seg = data['DNA']\n",
    "\n",
    "##### TO DO #######\n",
    "\n",
    "net = DeepDNA(101)\n",
    "out = net(dna_seg)\n",
    "\n",
    "print(\"the output of the model \", out[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFzp7DbtlTwG",
    "outputId": "24e73025-a469-4042-b77f-d3d19ba0e2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepDNA(\n",
      "  (conv1): Conv1d(4, 16, kernel_size=(8,), stride=(1,), padding=same)\n",
      "  (conv2): Conv1d(16, 32, kernel_size=(8,), stride=(1,), padding=same)\n",
      "  (conv3): Conv1d(32, 64, kernel_size=(8,), stride=(1,), padding=same)\n",
      "  (lin1): Linear(in_features=6464, out_features=32, bias=True)\n",
      "  (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yypmG11hr_so"
   },
   "source": [
    "# Ex 8: Define loss function and optimizer\n",
    "\n",
    "\n",
    "1. Define an SGD optimizer for the model. You need to choose the learning rate for your model.\n",
    "\n",
    "2. Define a Binary Cross Entropy (BCE) Loss  function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZwQKSrxh1A_"
   },
   "outputs": [],
   "source": [
    "## TODO ###\n",
    "import numpy as np\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rEjVjhetI6A"
   },
   "source": [
    "# Ex 9: Training your model\n",
    "\n",
    "The following function allows to train the model for one epoch. This function returns total loss per epoch.\n",
    "Implement the training pass for this function.\n",
    "\n",
    "\n",
    "\n",
    "The general process with PyTorch for one learning step consits of several steps:\n",
    "\n",
    "1. Make a forward pass through the network\n",
    "2. Use the network output to calculate the loss\n",
    "3. Perform a backward pass through the network with loss.backward() to calculate the gradients\n",
    "4. Take a step with the optimizer to update the weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAil9eU9iNCf"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    loss_epoch = 0\n",
    "    for batch_data in train_loader:\n",
    "\n",
    "\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pz0VV2Oenftq"
   },
   "source": [
    "# Ex 11: Accuracy Calculation\n",
    "\n",
    "Write a function named **compute_num_correct_pred(y_prob, y_label)** that allows to compute the number of correct predictions. **y_prob** and **y_label** should be pytorch tensors.\n",
    "\n",
    "For example,\n",
    "y_prob = [[0.3],[0.4], [0.8], [0.7]].\n",
    "\n",
    "y = [[0], [1], [1], [0]].\n",
    "\n",
    "This function should return 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JZ3cRawWpFe7"
   },
   "outputs": [],
   "source": [
    "### TODO ####\n",
    "def compute_num_correct_pred(y_prob, y_label):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N_g4DA-vex8"
   },
   "source": [
    "\n",
    "The function below allows to calculate the accuracy of the model on dataset loader. Execute this function to see if you implemented the compute_num_correct_pred function correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FY9V2-NCvv25"
   },
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "  net.eval()\n",
    "\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data in loader:\n",
    "      dna = data['DNA']\n",
    "      y = data['Class']\n",
    "\n",
    "      out = net(dna)\n",
    "      correct += compute_num_correct_pred(out, y)\n",
    "\n",
    "  return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0vTKeeQ3wGb"
   },
   "source": [
    "# Ex 12: Training the model\n",
    "\n",
    "The code below allows to train your model on 10 epoches. If all work well, you should see the training loss drop with each epoch.\n",
    "\n",
    "train the model for 2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-vkWpKLixGE",
    "outputId": "7f41715a-8840-4529-cb4c-c6f76d84bf5e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX_FGbp4tV0Z"
   },
   "source": [
    "# Ex13 (optional)\n",
    "\n",
    "\n",
    "\n",
    "1. If we use torch.nn.BCEWithLogitsLoss(), what does we need to change to the definition of the model ?\n",
    "\n",
    "\n",
    "\n",
    "2. The same question for torch.nn.CrossEntropyLoss() loss.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0l-GFUSOmOIr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
