{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-10T13:52:19.554753Z","iopub.execute_input":"2024-10-10T13:52:19.555294Z","iopub.status.idle":"2024-10-10T13:52:19.563257Z","shell.execute_reply.started":"2024-10-10T13:52:19.555248Z","shell.execute_reply":"2024-10-10T13:52:19.562079Z"},"trusted":true},"outputs":[],"execution_count":41},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nimport copy\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.569063Z","iopub.execute_input":"2024-10-10T13:52:19.569893Z","iopub.status.idle":"2024-10-10T13:52:19.582092Z","shell.execute_reply.started":"2024-10-10T13:52:19.569842Z","shell.execute_reply":"2024-10-10T13:52:19.580574Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def load_data():\n    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n    \n    # mnist\n    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n    \n    # mnist for each model\n    indices = np.random.permutation(len(train_dataset))\n    subset1 = Subset(train_dataset, indices[:600])\n    subset2 = Subset(train_dataset, indices[600:1200])\n    \n    train_loader1 = DataLoader(subset1, batch_size=50, shuffle=True)\n    train_loader2 = DataLoader(subset2, batch_size=50, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n    \n    return train_loader1, train_loader2, test_loader","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.584743Z","iopub.execute_input":"2024-10-10T13:52:19.585234Z","iopub.status.idle":"2024-10-10T13:52:19.596446Z","shell.execute_reply.started":"2024-10-10T13:52:19.585181Z","shell.execute_reply":"2024-10-10T13:52:19.595096Z"},"trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n        self.conv2 = nn.Conv2d(32, 128, 3, padding=1)\n        self.dropout = nn.Dropout(0.3)\n        self.fc1 = nn.Linear(128 * 7 * 7, 10)\n\n    def forward(self, x):\n        x = torch.relu(self.conv1(x))\n        x = torch.max_pool2d(x, 2)\n        x = torch.relu(self.conv2(x))\n        x = torch.max_pool2d(x, 2)\n        x = self.dropout(x)\n        x = x.view(x.size(0), -1)  # Flatten\n        x = torch.relu(self.fc1(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.598683Z","iopub.execute_input":"2024-10-10T13:52:19.599140Z","iopub.status.idle":"2024-10-10T13:52:19.610247Z","shell.execute_reply.started":"2024-10-10T13:52:19.599076Z","shell.execute_reply":"2024-10-10T13:52:19.608840Z"},"trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def train_model(model, train_loader, epochs=1):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01)\n    \n    model.train()\n    for epoch in range(epochs):\n        for images, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n\ndef evaluate_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    return 100 * correct / total\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.615658Z","iopub.execute_input":"2024-10-10T13:52:19.616132Z","iopub.status.idle":"2024-10-10T13:52:19.628819Z","shell.execute_reply.started":"2024-10-10T13:52:19.616089Z","shell.execute_reply":"2024-10-10T13:52:19.627395Z"},"trusted":true},"outputs":[],"execution_count":45},{"cell_type":"code","source":"def average_model_parameters(models, average_weights):\n    averaged_params = copy.deepcopy(models[0].state_dict())\n    \n    for key in averaged_params.keys():\n        averaged_params[key] = sum(weight * models[i].state_dict()[key] for i, weight in enumerate(average_weights))\n    \n    return averaged_params\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.631525Z","iopub.execute_input":"2024-10-10T13:52:19.632112Z","iopub.status.idle":"2024-10-10T13:52:19.641470Z","shell.execute_reply.started":"2024-10-10T13:52:19.632053Z","shell.execute_reply":"2024-10-10T13:52:19.639905Z"},"trusted":true},"outputs":[],"execution_count":46},{"cell_type":"code","source":"def update_model_parameters(model, new_params):\n    model.load_state_dict(new_params)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.643629Z","iopub.execute_input":"2024-10-10T13:52:19.644080Z","iopub.status.idle":"2024-10-10T13:52:19.654030Z","shell.execute_reply.started":"2024-10-10T13:52:19.644029Z","shell.execute_reply":"2024-10-10T13:52:19.652806Z"},"trusted":true},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def federated_learning(train_loader1, train_loader2, test_loader):\n    model1 = SimpleCNN()\n    model2 = SimpleCNN()\n    \n    rounds = 10\n    for i in range(rounds):\n        train_model(model1, train_loader1, epochs=5)\n        train_model(model2, train_loader2, epochs=5)\n        \n        acc1_before = evaluate_model(model1, test_loader)\n        print(f\"Accuracy of model 1 before averaging: {acc1_before:.2f}%\")\n\n        acc2_before = evaluate_model(model2, test_loader)\n        print(f\"Accuracy of model 2 before averaging: {acc2_before:.2f}%\")\n\n        average_weights = [0.5, 0.5]\n        averaged_params = average_model_parameters([model1, model2], average_weights)\n        \n        update_model_parameters(model1, averaged_params)\n        update_model_parameters(model2, averaged_params)\n\n        \n\n#     acc1_before = evaluate_model(model1, test_loader)\n#     print(f\"Accuracy of model 1 before averaging: {acc1_before:.2f}%\")\n    \n#     acc2_before = evaluate_model(model2, test_loader)\n#     print(f\"Accuracy of model 2 before averaging: {acc2_before:.2f}%\")\n\n#     average_weights = [0.5, 0.5]\n#     averaged_params = average_model_parameters([model1, model2], average_weights)\n\n#     averaged_model = SimpleCNN()\n#     update_model_parameters(averaged_model, averaged_params)\n\n    averaged_acc = evaluate_model(averaged_model, test_loader)\n    print(f\"Accuracy of averaged model: {averaged_acc:.2f}%\")\n\n    return acc1_before, acc2_before, averaged_acc\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.690702Z","iopub.execute_input":"2024-10-10T13:52:19.691235Z","iopub.status.idle":"2024-10-10T13:52:19.702719Z","shell.execute_reply.started":"2024-10-10T13:52:19.691188Z","shell.execute_reply":"2024-10-10T13:52:19.701099Z"},"trusted":true},"outputs":[],"execution_count":48},{"cell_type":"code","source":"train_loader1, train_loader2, test_loader = load_data()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.705282Z","iopub.execute_input":"2024-10-10T13:52:19.706885Z","iopub.status.idle":"2024-10-10T13:52:19.843254Z","shell.execute_reply.started":"2024-10-10T13:52:19.706821Z","shell.execute_reply":"2024-10-10T13:52:19.841828Z"},"trusted":true},"outputs":[],"execution_count":49},{"cell_type":"code","source":"acc1_before, acc2_before, averaged_acc = federated_learning(train_loader1, train_loader2, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T13:52:19.844886Z","iopub.execute_input":"2024-10-10T13:52:19.845298Z","iopub.status.idle":"2024-10-10T13:56:57.811813Z","shell.execute_reply.started":"2024-10-10T13:52:19.845256Z","shell.execute_reply":"2024-10-10T13:56:57.809985Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy of model 1 before averaging: 56.02%\nAccuracy of model 2 before averaging: 56.52%\nAccuracy of model 1 before averaging: 68.51%\nAccuracy of model 2 before averaging: 62.86%\nAccuracy of model 1 before averaging: 81.10%\nAccuracy of model 2 before averaging: 76.12%\nAccuracy of model 1 before averaging: 84.79%\nAccuracy of model 2 before averaging: 83.91%\nAccuracy of model 1 before averaging: 86.63%\nAccuracy of model 2 before averaging: 86.30%\nAccuracy of model 1 before averaging: 88.04%\nAccuracy of model 2 before averaging: 87.51%\nAccuracy of model 1 before averaging: 88.08%\nAccuracy of model 2 before averaging: 88.94%\nAccuracy of model 1 before averaging: 89.56%\nAccuracy of model 2 before averaging: 89.57%\nAccuracy of model 1 before averaging: 89.34%\nAccuracy of model 2 before averaging: 89.79%\nAccuracy of model 1 before averaging: 90.30%\nAccuracy of model 2 before averaging: 90.32%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acc1_before, acc2_before, averaged_acc \u001b[38;5;241m=\u001b[39m \u001b[43mfederated_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[48], line 36\u001b[0m, in \u001b[0;36mfederated_learning\u001b[0;34m(train_loader1, train_loader2, test_loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m         update_model_parameters(model2, averaged_params)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     acc1_before = evaluate_model(model1, test_loader)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#     print(f\"Accuracy of model 1 before averaging: {acc1_before:.2f}%\")\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#     averaged_model = SimpleCNN()\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#     update_model_parameters(averaged_model, averaged_params)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     averaged_acc \u001b[38;5;241m=\u001b[39m evaluate_model(\u001b[43maveraged_model\u001b[49m, test_loader)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy of averaged model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maveraged_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acc1_before, acc2_before, averaged_acc\n","\u001b[0;31mNameError\u001b[0m: name 'averaged_model' is not defined"],"ename":"NameError","evalue":"name 'averaged_model' is not defined","output_type":"error"}],"execution_count":50}]}